PROMPT: Import file data to dynamodb nodejs, express code example

RESPONSE: 

Absolutely! Here’s a clean example of **importing a file (CSV or JSON) into DynamoDB** using **Node.js + Express**. This uses `multer` for file uploads and AWS SDK v3 for DynamoDB operations.

---

### 1️⃣ Install dependencies

```bash
npm install express multer @aws-sdk/client-dynamodb @aws-sdk/lib-dynamodb csv-parser
```

* `multer` → handles file uploads
* `csv-parser` → parses CSV files
* AWS SDK v3 → DynamoDB operations

---

### 2️⃣ Express app example

```ts
import express from "express";
import multer from "multer";
import fs from "fs";
import csv from "csv-parser";
import { DynamoDBClient } from "@aws-sdk/client-dynamodb";
import { DynamoDBDocumentClient, PutCommand } from "@aws-sdk/lib-dynamodb";

const app = express();
const port = 3000;

// AWS DynamoDB client
const client = new DynamoDBClient({ region: "us-east-1" });
const ddbDocClient = DynamoDBDocumentClient.from(client);

// Multer setup
const upload = multer({ dest: "uploads/" });

app.post("/import", upload.single("file"), async (req, res) => {
  if (!req.file) return res.status(400).send("No file uploaded");

  const filePath = req.file.path;
  const tableName = "YourTableName";
  const items: any[] = [];

  // Assuming CSV file
  fs.createReadStream(filePath)
    .pipe(csv())
    .on("data", (row) => {
      items.push(row); // store each row for batch insert
    })
    .on("end", async () => {
      try {
        // Insert each row into DynamoDB
        for (const item of items) {
          await ddbDocClient.send(
            new PutCommand({
              TableName: tableName,
              Item: item,
            })
          );
        }

        fs.unlinkSync(filePath); // delete temp uploaded file
        res.send({ message: "File imported successfully", count: items.length });
      } catch (err) {
        console.error(err);
        res.status(500).send({ error: "Failed to import file" });
      }
    });
});

app.listen(port, () => {
  console.log(`Server running at http://localhost:${port}`);
});
```

---

### ⚡ Notes:

1. **File type**: This example is for **CSV files**. For JSON files, you can use `JSON.parse(fs.readFileSync(filePath, "utf-8"))`.
2. **Batch write**: For large datasets, consider using **`BatchWriteCommand`** instead of inserting items one by one to improve performance.
3. **Field mapping**: Ensure CSV headers match your DynamoDB table attribute names.

---

I can also write an **optimized version using BatchWriteCommand and streaming**, which is faster and safer for large CSV files.

Do you want me to do that?
